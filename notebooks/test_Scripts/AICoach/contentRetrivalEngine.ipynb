{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "12379723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, urllib.parse, datetime, re\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from supabase import create_client\n",
    "from streamlit_navigation_bar import st_navbar\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import spacy\n",
    "import dateparser\n",
    "from dateparser.search import search_dates\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9f2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1f65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findTableNTime(keywords,prompt):\n",
    "#     table_list =[]\n",
    "#     dates = []\n",
    "#     for word in prompt.split(\" \"):\n",
    "#         for table , keys in keywords.items():\n",
    "#             for k in keys:\n",
    "#                 if k in word:\n",
    "#                     table_list.append(table)\n",
    "#     dates = dateparser.search.search_dates(prompt)\n",
    "#     return table_list,dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3655b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def detect_tables_n_dates(nlp,text):\n",
    "    #keywords : Data,Time,Filter\n",
    "    Keywords_Table = { \"stress\": [\"stress\", \"stress level\", \"stress score\", \"tension\", \"anxiety\", \"strain\", \"mental load\", \"stress pattern\", \"stress zones\", \"stress chart\"],\n",
    "        \"hr\":[\"heart rate\", \"hr\", \"bpm\", \"resting heart rate\", \"max heart rate\", \"pulse\",\"cardio\", \"hr zone\", \"heart beat\", \"heart-rate\",\"heart\"],\n",
    "        \"spo2\":[\"spo2\", \"oxygen\", \"blood oxygen\", \"oxygen saturation\", \"o2 level\",\"breathing\", \"respiration\", \"air levels\", \"oxygen dips\", \"oxygen score\"],\n",
    "        \"steps\":[\"steps\", \"step count\", \"walking\", \"walk\", \"daily steps\", \"distance walked\",\"movement\", \"stride\", \"pedometer\", \"step goal\"],\n",
    "        \"calorie\": [\"calories\", \"calorie burn\", \"energy burn\", \"burned\", \"metabolism\",\"active calories\", \"basal calories\", \"kcal\", \"energy expenditure\", \"fat burn\",\"cal\"],\n",
    "        \"exercise\": [\"exercise\", \"workout\", \"training\", \"session\", \"sports\", \"activity\",\"reps\", \"sets\", \"routine\", \"intensity\",\"activities\"],    \n",
    "        }\n",
    "    text = text.lower()    \n",
    "    doc = nlp(text)\n",
    "    words_to_dates = {}\n",
    "    dates_total = []\n",
    "    table_list =[]\n",
    "    table_word = \"\" ## to make sure the table name isnt accidently used as a date\n",
    "    for word in text.split(\" \"):\n",
    "        for table , keys in Keywords_Table.items():\n",
    "            for k in keys:\n",
    "                if k in word:\n",
    "                    table_list.append(table)\n",
    "                    table_word = word\n",
    "\n",
    "    ## spacy entity dates + dateparser.parse()\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            parsed = dateparser.parse(ent.text)\n",
    "            if parsed and ent.text not in table_word:\n",
    "                words_to_dates[ent.text] = parsed\n",
    "    # \n",
    "    dp_res = search_dates(text,languages=[\"en\"])\n",
    "    if dp_res:\n",
    "        for phrase, dt in dp_res:\n",
    "            if phrase not in table_word:\n",
    "                words_to_dates[phrase] = dt\n",
    "\n",
    "    ###########################################################\n",
    "    ##REGEX\n",
    "    MONTHS = r\"(?:january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\"\n",
    "\n",
    "\n",
    "    patterns = [\n",
    "        # dd/mm/yyyy | dd-mm-yyyy | dd.mm.yyyy\n",
    "        r\"\\b\\d{1,2}[\\/\\-.]\\d{1,2}[\\/\\-.]\\d{2,4}\\b\",\n",
    "\n",
    "        # yyyy-mm-dd\n",
    "        r\"\\b\\d{4}-\\d{1,2}-\\d{1,2}\\b\",\n",
    "\n",
    "        # 12 Aug 2025\n",
    "        rf\"\\b\\d{{1,2}}(?:st|nd|rd|th)?\\s+{MONTHS}\\s+\\d{{4}}\\b\",\n",
    "\n",
    "        # Aug 12 2025\n",
    "        rf\"\\b{MONTHS}\\s+\\d{{1,2}}(?:st|nd|rd|th)?\\s+\\d{{4}}\\b\",\n",
    "\n",
    "        # August 12, 2025\n",
    "        rf\"\\b{MONTHS}\\s+\\d{{1,2}}(?:st|nd|rd|th)?,\\s+\\d{{4}}\\b\",\n",
    "\n",
    "        # 12th August\n",
    "        rf\"\\b\\d{{1,2}}(?:st|nd|rd|th)?\\s+{MONTHS}\\b\",\n",
    "\n",
    "        # Standalone month\n",
    "        rf\"\\b{MONTHS}\\b\",\n",
    "    ]\n",
    "\n",
    "    found = []\n",
    "    for p in patterns:\n",
    "        matches = re.findall(p, text)\n",
    "        for m in matches:\n",
    "            found.append(m.strip())\n",
    "\n",
    "    # Remove standalone month if part of a larger match\n",
    "    filtered = []\n",
    "    for f in found:\n",
    "        if any((f != other and f in other) for other in found):\n",
    "            continue\n",
    "        filtered.append(f)\n",
    "\n",
    "    # Unique + order preserved    \n",
    "\n",
    "    dates_regex = list(dict.fromkeys(filtered))\n",
    "\n",
    "\n",
    "\n",
    "    # removing duplicates\n",
    "    seen_dates = set()\n",
    "    new_words_2_date_dict = {}\n",
    "    for k , v in words_to_dates.items():\n",
    "        date_only = v.date() # removing hr/min/secs\n",
    "        if date_only not in seen_dates:\n",
    "            new_words_2_date_dict[k] = v\n",
    "            seen_dates.add(date_only)\n",
    "\n",
    "    return table_list,dates_regex,new_words_2_date_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------------------------------------------------\n",
    "# # TEST SUITE\n",
    "# # -------------------------------------------------------------\n",
    "\n",
    "# test_cases = {\n",
    "#     # Month-only (case variations)\n",
    "#     \"aug\": [\"aug\"],\n",
    "#     \"Aug\": [\"aug\"],\n",
    "#     \"AUG\": [\"aug\"],\n",
    "#     \"august\": [\"august\"],\n",
    "#     \"August\": [\"august\"],\n",
    "\n",
    "#     # All together\n",
    "#     \"aug, Aug, AUG, august, August\": [\"aug\", \"aug\", \"aug\", \"august\", \"august\"],\n",
    "\n",
    "#     # Numeric formats\n",
    "#     \"12/18/25\": [\"12/18/25\"],\n",
    "#     \"01/02/2025\": [\"01/02/2025\"],\n",
    "#     \"1-2-25\": [\"1-2-25\"],\n",
    "#     \"2025-11-18\": [\"2025-11-18\"],\n",
    "\n",
    "#     # Month + day + year\n",
    "#     \"12 Aug 2025\": [\"12 aug 2025\"],\n",
    "#     \"Aug 12 2025\": [\"aug 12 2025\"],\n",
    "#     \"August 12, 2025\": [\"august 12, 2025\"],\n",
    "\n",
    "#     # Ordinal\n",
    "#     \"12th August\": [\"12th august\"],\n",
    "#     \"August 3rd 2024\": [\"august 3 2024\"],\n",
    "\n",
    "#     # Dot/dash\n",
    "#     \"12.10.2025\": [\"12.10.2025\"],\n",
    "#     \"3.1.25\": [\"3.1.25\"],\n",
    "\n",
    "#     # Mixed scenarios\n",
    "#     \"I will come on 1st January 2025 or maybe Feb 2025\":\n",
    "#         [\"1st january 2025\", \"february\"],\n",
    "\n",
    "#     \"Dates: Aug 24, 2024-11-18, 2025\":\n",
    "#         [\"aug 24\", \"2024\", \"2025\"],\n",
    "\n",
    "#     # Noise text\n",
    "#     \"no dates here\":\n",
    "#         []\n",
    "# }\n",
    "\n",
    "# print(\"\\n=== TEST RESULTS ===\")\n",
    "\n",
    "# for text, expected in test_cases.items():\n",
    "#     result = detect_dates_all(Keywords_Table,text)\n",
    "\n",
    "    \n",
    "#     print(f\"\\nInput: {text}\")\n",
    "#     print(f\"Expected: {sorted(set(expected))}\")\n",
    "#     print(f\"Got      : {sorted(set(result))}\")\n",
    "\n",
    "#     if set(result) == set(expected):\n",
    "#         print(\"➡️ PASS\")\n",
    "#     else:\n",
    "#         print(\"❌ FAIL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57789614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MONTHS = {\n",
    "    \"jan\": 1, \"january\": 1,\n",
    "    \"feb\": 2, \"february\": 2,\n",
    "    \"mar\": 3, \"march\": 3,\n",
    "    \"apr\": 4, \"april\": 4,\n",
    "    \"may\": 5,\n",
    "    \"jun\": 6, \"june\": 6,\n",
    "    \"jul\": 7, \"july\": 7,\n",
    "    \"aug\": 8, \"august\": 8,\n",
    "    \"sep\": 9, \"sept\": 9, \"september\": 9,\n",
    "    \"oct\": 10, \"october\": 10,\n",
    "    \"nov\": 11, \"november\": 11,\n",
    "    \"dec\": 12, \"december\": 12\n",
    "}\n",
    "\n",
    "def standardize_date(date_str, current_year=None):    \n",
    "    \n",
    "    # if its datetime.datetime\n",
    "    if isinstance(date_str,datetime):\n",
    "        y = date_str.year\n",
    "        m = date_str.month\n",
    "        d = date_str.day\n",
    "\n",
    "        return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "        \n",
    "    # if its a string\n",
    "    date_str = date_str.lower().strip()\n",
    "\n",
    "    if current_year is None:\n",
    "        current_year = datetime.now().year\n",
    "\n",
    "    # Remove suffixes: 12th -> 12\n",
    "    date_str = re.sub(r\"(\\d+)(st|nd|rd|th)\", r\"\\1\", date_str)\n",
    "\n",
    "    # ---------- CASE 1: YYYY-MM-DD ----------\n",
    "    if re.match(r\"^\\d{4}-\\d{1,2}-\\d{1,2}$\", date_str):\n",
    "        y, m, d = map(int, date_str.split(\"-\"))\n",
    "        return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "\n",
    "    # ---------- CASE 2: DD/MM/YY or DD/MM/YYYY ----------\n",
    "    if \"/\" in date_str:\n",
    "        parts = date_str.split(\"/\")\n",
    "        if len(parts) == 3:\n",
    "            d, m, y = parts\n",
    "            d, m, y = int(d), int(m), int(y)\n",
    "            if y < 100: y += 2000\n",
    "            return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "\n",
    "    # ---------- CASE 3: DD.MM.YY or DD.MM.YYYY ----------\n",
    "    if \".\" in date_str:\n",
    "        parts = date_str.split(\".\")\n",
    "        if len(parts) == 3:\n",
    "            d, m, y = parts\n",
    "            d, m, y = int(d), int(m), int(y)\n",
    "            if y < 100: y += 2000\n",
    "            return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "\n",
    "    # ---------- CASE 4: DD-MM-YY or DD-MM-YYYY ----------\n",
    "    if \"-\" in date_str:\n",
    "        parts = date_str.split(\"-\")\n",
    "        if len(parts) == 3 and not re.match(r\"^\\d{4}-\", date_str):\n",
    "            d, m, y = parts\n",
    "            d, m, y = int(d), int(m), int(y)\n",
    "            if y < 100: y += 2000\n",
    "            return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "\n",
    "    # ---------- CASE 5: Mixed Month + Day + Optional Year ----------\n",
    "    tokens = date_str.replace(\",\", \"\").split()\n",
    "\n",
    "    # Find month\n",
    "    month = None\n",
    "    for t in tokens:\n",
    "        if t in MONTHS:\n",
    "            month = MONTHS[t]\n",
    "            break\n",
    "\n",
    "    if month:\n",
    "        # find day (1–31)\n",
    "        day = None\n",
    "        for t in tokens:\n",
    "            if t.isdigit() and 1 <= int(t) <= 31:\n",
    "                day = int(t)\n",
    "                break\n",
    "\n",
    "        # find year ( >31 )\n",
    "        year = None\n",
    "        for t in tokens:\n",
    "            if t.isdigit() and int(t) > 31:\n",
    "                year = int(t)\n",
    "                break\n",
    "\n",
    "        if year is None:\n",
    "            year = current_year\n",
    "\n",
    "        if year < 100:\n",
    "            year += 2000\n",
    "\n",
    "        if day:\n",
    "            return f\"{year:04d}-{month:02d}-{day:02d}\"\n",
    "\n",
    "    # ---------- CASE 6: Only month → return YYYY-MM-01 ----------\n",
    "    if date_str in MONTHS:\n",
    "        return f\"{current_year:04d}-{MONTHS[date_str]:02d}-01\"\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebca6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-12\n",
      "2025-08-12\n",
      "2025-08-24\n",
      "2025-01-01\n",
      "2025-01-03\n",
      "2025-11-18\n",
      "2025-08-01\n",
      "2025-08-12\n"
     ]
    }
   ],
   "source": [
    "# # standardize_date(\"12 Aug 2025\")      #→ \"2025-08-12\"\n",
    "# # standardize_date(\"12th August\")      # → \"2025-08-12\"  (uses current year)\n",
    "# # standardize_date(\"Aug 24, 2025\")     # → \"2025-08-24\"\n",
    "# # standardize_date(\"1st January 2025\") # → \"2025-01-01\"\n",
    "# # standardize_date(\"3.1.25\")           #→ \"2025-01-03\"\n",
    "# # standardize_date(\"2025-11-18\")       # → \"2025-11-18\"\n",
    "# # standardize_date(\"aug\")               #→ \"2025-08-01\"\n",
    "# # standardize_date(\"Aug 12\")            #→ \"2025-08-12\"  (uses current year)\n",
    "# test_inputs = [\n",
    "#     \"12 Aug 2025\",\n",
    "#     \"12th August\",\n",
    "#     \"Aug 24, 2025\",\n",
    "#     \"1st January 2025\",\n",
    "#     \"3.1.25\",\n",
    "#     \"2025-11-18\",\n",
    "#     \"aug\",\n",
    "#     \"Aug 12\"\n",
    "# ]\n",
    "\n",
    "# for i in test_inputs:\n",
    "#     print(standardize_date(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1dce704d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stress'] \n",
      " {'6 october': '2025-10-06'}\n"
     ]
    }
   ],
   "source": [
    "def parse_prompt(nlp,Prompt):\n",
    "    tables, dates2dates, words2dates = detect_tables_n_dates(nlp,Prompt)\n",
    "    # print(tables)\n",
    "    standardized_dates2dates = {}\n",
    "    for t in dates2dates:\n",
    "        standardized_dates2dates[t] = standardize_date(t)\n",
    "    standardized_words2dates = {}\n",
    "    for key, value in words2dates.items():\n",
    "        standardized_words2dates[key] = standardize_date(value)\n",
    "\n",
    "\n",
    "    final_dates = {**standardized_dates2dates, **standardized_words2dates}\n",
    "    return tables, final_dates\n",
    "\n",
    "\n",
    "# Prompt = input(\"Enter Prompt:\")\n",
    "Prompt = \"How was my hr between 24 nov and 23 nov n this week n yesterday n last week n november n last month\"\n",
    "Prompt = \"heart rate from  12 jul to  12 august\"\n",
    "Prompt = \"stress at 6 october \"\n",
    "tables , phrase_date_pair = parse_prompt(nlp,Prompt)\n",
    "print(tables, \"\\n\", phrase_date_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e89df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12 jul': '2025-07-12', '12 august': '2025-08-12', 'august': '2025-08-20'}\n",
      "fetch a day: 12 jul\n",
      "fetch a day: 12 august\n",
      "fetch a month: august\n",
      "2025-07-12\n",
      "2025-08-12\n"
     ]
    }
   ],
   "source": [
    "# ## Now we take the 'phrase : date' pair and create context for filtering the detected tables\n",
    "# print(phrase_date_pair)\n",
    "\n",
    "# ## cases:\n",
    "# ## case 1: data for one or more date to be fetched (all dates which are specified) eg: 24 nov, yesterday\n",
    "# ## case 2: data for one or more week to be fetched (all dates which are specified) eg: last week, this week\n",
    "# ## case 3: data for one or more month to be fetched (all months which are specified) eg : aug, last month, this month\n",
    "# ## case 4: a range of data from one date to another is to be fetched (both dates which are specified) eg: [23 nov, 30 nov], [1 aug, 18 aug]\n",
    "\n",
    "# # logic: \n",
    "# # for fetching dates: check for patterns in phrases like : 24 nov, yesterday, today\n",
    "# # for fetching weeks: check for patterns in phrases like : last week, this week\n",
    "# # for fetching months: check for patterns in phrases like: month names \n",
    "# # for fetching range: check for keywords in received prompt like: from .. to .. \n",
    "\n",
    "# # phrases\n",
    "# pattern = r\"\\b\\d{1,2}\\s+(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|june|july|august|september|october|november|december)\\b\"\n",
    "# phrases = [\"yesterday\",\"today\"]\n",
    "# # month_patterns = r\"(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|may|june|july|august|september|october|november|december)\"\n",
    "\n",
    "# month_patterns = r\"(?:january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\"\n",
    "# range_pattern = rf\"from\\s+((?:\\d{{1,2}}(?:st|nd|rd|th)?\\s+)?{month_patterns})\\s+to\\s+((?:\\d{{1,2}}(?:st|nd|rd|th)?\\s+)?{month_patterns})\"\n",
    "\n",
    "# for key, value in phrase_date_pair.items():\n",
    "#     if re.fullmatch(pattern, key.lower()) or key in phrases:\n",
    "#         print(f'fetch a day: {key}') \n",
    "#         # now fetch all the entries matching this date \n",
    "#     elif 'week' in key:\n",
    "#         print('fetch a week:',key)\n",
    "#         # now fetch all the entries present on this dates week\n",
    "#     elif 'month' in key or re.fullmatch(month_patterns, key.lower()):\n",
    "#         print('fetch a month:',key)\n",
    "#         # now fetch all the entries matching this dates month\n",
    "\n",
    "\n",
    "# r = re.search(range_pattern, Prompt, re.IGNORECASE)\n",
    "# if r:\n",
    "#     # print('range found:',r.group(0))\n",
    "#     print(phrase_date_pair[r.group(1)]) # from date\n",
    "#     print(phrase_date_pair[r.group(2)]) # to date\n",
    "\n",
    "#     # now fetch all the entries that between from date and to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dc3de603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def apply_offset(row, offset_col, time_col):\n",
    "    offset_val = row[offset_col]\n",
    "    if pd.isnull(offset_val):\n",
    "        return row[time_col]\n",
    "    offset_str = str(offset_val)\n",
    "    match = None\n",
    "    # Accept both \"UTC+0530\" and \"+05:30\" formats\n",
    "    if offset_str.startswith(\"UTC\"):\n",
    "        match = re.match(r\"UTC([+-])(\\d{2})(\\d{2})\", offset_str)\n",
    "    else:\n",
    "        match = re.match(r\"([+-])(\\d{2}):?(\\d{2})\", offset_str)\n",
    "    if match:\n",
    "        sign, hh, mm = match.groups()\n",
    "        hours, minutes = int(hh), int(mm)\n",
    "        delta = timedelta(hours=hours, minutes=minutes)\n",
    "        if sign == \"-\":\n",
    "            delta = -delta\n",
    "        return row[time_col] + delta\n",
    "    return row[time_col]\n",
    "\n",
    "# -------------------- Cache -----------------------#\n",
    "def get_supabase_client():\n",
    "    load_dotenv()\n",
    "    url = os.getenv(\"url\")\n",
    "    key = os.getenv(\"key\")\n",
    "    return create_client(url, key)\n",
    "\n",
    "def get_engine():\n",
    "    load_dotenv()\n",
    "    return create_engine(\n",
    "        f\"postgresql+psycopg2://{os.getenv('user')}:{urllib.parse.quote_plus(os.getenv('password'))}@{os.getenv('host')}:{os.getenv('port')}/{os.getenv('dbname')}\",\n",
    "        pool_pre_ping=True,  # checks if connection is alive\n",
    "        pool_recycle=1800    # recycle every 30 mins\n",
    "    )\n",
    "\n",
    "\n",
    "def querySupabase(_engine, table: str, columns: list, retries=3):\n",
    "    #Query Supabase/Postgres with retry logic.\n",
    "    cols_str = \",\".join(columns)\n",
    "    query = text(f\"SELECT {cols_str} FROM {table}\")\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            with _engine.connect() as conn:\n",
    "                df = pd.read_sql(query, conn)\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                st.warning(f\"Query failed, retryingg... ({attempt + 1}/{retries}) — {e}\")                \n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                st.error(f\"Query failed after {retries} attempts: {e}\")\n",
    "                raise e\n",
    "\n",
    "\n",
    "# -------------------- Metric Config --------------------#\n",
    "METRICS_CONFIG = {\n",
    "    \"stress\": {\n",
    "        \"table\": \"stress\",\n",
    "        \"columns\": [\"start_time\", \"score\",\"min\",\"max\", \"time_offset\", \"binning_data\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.stress/{0}/{1}\",\n",
    "    },\n",
    "    \"hr\": {\n",
    "        \"table\": \"tracker_heart_rate\",\n",
    "        \"columns\": [\"heart_rate_start_time\", \"heart_rate_heart_rate\", \"heart_rate_min\", \"heart_rate_max\", \"heart_rate_time_offset\", \"heart_rate_heart_beat_count\", \"heart_rate_deviceuuid\", \"heart_rate_binning_data\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.tracker.heart_rate/{0}/{1}\",\n",
    "    },\n",
    "    \"spo2\": {\n",
    "        \"table\": \"tracker_oxygen_saturation\",\n",
    "        \"columns\": [\"oxygen_saturation_start_time\", \"oxygen_saturation_spo2\",\"oxygen_saturation_heart_rate\", \"oxygen_saturation_time_offset\", \"oxygen_saturation_binning\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.tracker.oxygen_saturation/{0}/{1}\",\n",
    "    },\n",
    "    \"steps\": {\n",
    "        \"table\": \"tracker_pedometer_step_count\",\n",
    "        \"columns\": [\"step_count_start_time\", \"step_count_count\",\"run_step\",\"walk_step\",\"step_count_speed\",\"step_count_distance\",\"step_count_calorie\", \"step_count_time_offset\"],\n",
    "        \"jsonPath_template\": \"\",\n",
    "    },\n",
    "    \"calorie\": {\n",
    "        \"table\": \"calories_burned_details\",\n",
    "        \"columns\": [\"calories_burned_day_time\",\"calories_burned_create_time\",\"active_calories_goal\",\"total_exercise_calories\",\"calories_burned_tef_calorie\",\"calories_burned_active_time\",\"calories_burned_rest_calorie\",\"calories_burned_active_calorie\", \"extra_data\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.calories_burned.details/{0}/{1}\",\n",
    "    },\n",
    "    \"exercise\":{\n",
    "        \"table\":\"exercise\",\n",
    "        \"columns\": [\"exercise_start_time\",\"live_data_internal\",\"routine_datauuid\",\"custom_id\",\"exercise_duration\",\"exercise_calorie\",\"exercise_max_heart_rate\",\"exercise_min_heart_rate\",\"exercise_mean_heart_rate\",\"activity_type\",\"exercise_exercise_type\",\"exercise_count\",\"exercise_time_offset\",\"exercise_live_data\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.exercise/{0}/{1}\",        \n",
    "    },\n",
    "    \"exercise_routine\":{\n",
    "        \"table\":\"exercise_routine\",\n",
    "        \"columns\":[\"datauuid\",\"custom_id\",\"total_calorie\",\"activities\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.exercise.routine/{0}/{1}\",        \n",
    "    },\n",
    "    \"custom_exercise\":{\n",
    "        \"table\":\"exercise_custom_exercise\",\n",
    "        \"columns\":[\"custom_name\",\"datauuid\",\"custom_id\",\"custom_type\",\"preference\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.exercise.custom_exercise/{0}/{1}\",                \n",
    "    },\n",
    "    \"inbuilt_exercises\": {\n",
    "    \"table\": \"inbuilt_exercises\",\n",
    "    \"columns\":[\"exercise_type\",\"exercise_name\"],\n",
    "    \"jsonPath_template\" : \"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# -------------------- Warmup --------------------#\n",
    "def warmup():\n",
    "    \"\"\"Load all metrics into session and Supabase client safely.\"\"\"\n",
    "    supabase_client = get_supabase_client()\n",
    "    engine = get_engine()\n",
    "    \n",
    "    dataframes = {}\n",
    "    \n",
    "    def safe_jsonpath(val, template):\n",
    "        \"\"\"Generate jsonPath safely for binning columns.\"\"\"\n",
    "        if pd.isna(val) or val == \"\":\n",
    "            return \"\"\n",
    "        val_str = str(val)\n",
    "        first_char = val_str[0] if len(val_str) > 0 else \"\"\n",
    "        return template.format(first_char, val)\n",
    "    \n",
    "    for metric, cfg in METRICS_CONFIG.items():\n",
    "        # Query columns\n",
    "        df = querySupabase(engine, cfg[\"table\"], cfg[\"columns\"])\n",
    "        \n",
    "        # Add jsonPath column if template exists\n",
    "        if metric == 'exercise':\n",
    "            if cfg[\"jsonPath_template\"]:\n",
    "                bin_col1 = 'exercise_live_data'\n",
    "                bin_col2 = 'live_data_internal'\n",
    "                df['jsonPath_LiveData'] = df[bin_col1].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))\n",
    "                df['jsonPath_LiveInternal'] = df[bin_col2].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))            \n",
    "            else:\n",
    "                df['jsonPath_LiveData'] = \"\"\n",
    "                df['jsonPath_LiveInternal'] = \"\"\n",
    "        elif metric == 'exercise_routine':\n",
    "            if cfg[\"jsonPath_template\"]:\n",
    "                bin_col1 = 'activities'\n",
    "                df['jsonPath_activities'] = df[bin_col1].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))\n",
    "            else:\n",
    "                df['jsonPath_activities'] = \"\"\n",
    "        elif metric == 'custom_exercise':\n",
    "            if cfg[\"jsonPath_template\"]:\n",
    "                bin_col1 = 'preference'\n",
    "                df['jsonPath_preference'] = df[bin_col1].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))\n",
    "            else:\n",
    "                df['jsonPath_preference'] = \"\"                \n",
    "        else:\n",
    "            if cfg[\"jsonPath_template\"]:\n",
    "                bin_col = df.columns[-1]  # assume last column is the binning column\n",
    "                df['jsonPath'] = df[bin_col].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))\n",
    "            else:\n",
    "                df['jsonPath'] = \"\"\n",
    "\n",
    "        # ----------- Apply offset ONCE per metric -----------\n",
    "        # Stress\n",
    "        if metric == \"stress\" and \"time_offset\" in df.columns and \"start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"time_offset\", \"start_time\"), axis=1)\n",
    "        # Heart Rate\n",
    "        elif metric == \"hr\" and \"heart_rate_time_offset\" in df.columns and \"heart_rate_start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"heart_rate_time_offset\", \"heart_rate_start_time\"), axis=1)\n",
    "        # SpO2\n",
    "        elif metric == \"spo2\" and \"oxygen_saturation_time_offset\" in df.columns and \"oxygen_saturation_start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"oxygen_saturation_time_offset\", \"oxygen_saturation_start_time\"), axis=1)\n",
    "        # Steps\n",
    "        elif metric == \"steps\" and \"step_count_time_offset\" in df.columns and \"step_count_start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"step_count_time_offset\", \"step_count_start_time\"), axis=1)\n",
    "        # Calorie \n",
    "        elif metric == \"calorie\" and \"calories_burned_day_time\" in df.columns:\n",
    "            df[\"localized_time\"] = pd.to_datetime(df[\"calories_burned_day_time\"], errors=\"coerce\")\n",
    "        # Exercise\n",
    "        elif metric == \"exercise\" and \"exercise_time_offset\" in df.columns and \"exercise_start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"exercise_time_offset\", \"exercise_start_time\"), axis=1)\n",
    "        # -----------------------------------------------------\n",
    "\n",
    "        dataframes[metric] = df\n",
    "    \n",
    "    return supabase_client, dataframes\n",
    "\n",
    "supabase_client, dataframes = warmup()\n",
    "\n",
    "# removing old start_time and adding the localized time as start_time\n",
    "# removing unnecessary cols from the tables (jsonPath, binning, time offset)\n",
    "df = dataframes\n",
    "for key, value in df.items():\n",
    "    value = value.loc[:,~value.columns.str.contains(\"start_time\")]\n",
    "    value = value.loc[:,~value.columns.str.contains(\"time_offset\")]\n",
    "    value = value.loc[:,~value.columns.str.contains(\"jsonPath\")]\n",
    "    value = value.loc[:,~value.columns.str.contains(\"binning\")]\n",
    "    \n",
    "\n",
    "    value = value.rename(columns= lambda c: \"start_time\" if \"localized_time\" in c else c)\n",
    "    cols = value.columns.tolist()\n",
    "    if \"start_time\" in cols:\n",
    "        cols.insert(0, cols.pop(cols.index(\"start_time\")))\n",
    "        value = value[cols]\n",
    "    df[key] = value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3e7ec544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6 october': '2025-10-06'}\n",
      "fetch a day: 6 october -> 2025-10-06\n",
      "{'stress':              start_time  score   min    max\n",
      "856 2025-10-06 12:00:00   22.0   0.0  100.0\n",
      "857 2025-10-06 13:00:00   70.0  13.0  100.0\n",
      "858 2025-10-06 14:00:00   41.0   0.0  100.0\n",
      "859 2025-10-06 15:00:00   34.0   7.0   61.0\n",
      "860 2025-10-06 17:00:00   53.0   0.0  100.0\n",
      "861 2025-10-06 18:00:00   78.0  15.0  100.0}\n"
     ]
    }
   ],
   "source": [
    "## Now we take the 'phrase : date' pair and create context for filtering the detected tables\n",
    "print(phrase_date_pair)\n",
    "\n",
    "## cases:\n",
    "## case 1: data for one or more date to be fetched (all dates which are specified) eg: 24 nov, yesterday\n",
    "## case 2: data for one or more week to be fetched (all dates which are specified) eg: last week, this week\n",
    "## case 3: data for one or more month to be fetched (all months which are specified) eg : aug, last month, this month\n",
    "## case 4: a range of data from one date to another is to be fetched (both dates which are specified) eg: [23 nov, 30 nov], [1 aug, 18 aug]\n",
    "\n",
    "# logic: \n",
    "# for fetching dates: check for patterns in phrases like : 24 nov, yesterday, today\n",
    "# for fetching weeks: check for patterns in phrases like : last week, this week\n",
    "# for fetching months: check for patterns in phrases like: month names \n",
    "# for fetching range: check for keywords in received prompt like: from .. to .. \n",
    "\n",
    "# phrases\n",
    "pattern = r\"\\b\\d{1,2}\\s+(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|june|july|august|september|october|november|december)\\b\"\n",
    "phrases = [\"yesterday\",\"today\"]\n",
    "# month_patterns = r\"(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|may|june|july|august|september|october|november|december)\"\n",
    "\n",
    "month_patterns = r\"(?:january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\"\n",
    "range_pattern = rf\"from\\s+((?:\\d{{1,2}}(?:st|nd|rd|th)?\\s+)?{month_patterns})\\s+to\\s+((?:\\d{{1,2}}(?:st|nd|rd|th)?\\s+)?{month_patterns})\"\n",
    "\n",
    "\n",
    "# dataframes = df\n",
    "specified_dfs = {}\n",
    "for table in tables:\n",
    "    if table in df:\n",
    "        specified_dfs[table] = df[table] \n",
    "\n",
    "filtered_dfs = {}\n",
    "\n",
    "def filter_df(date,dfs):\n",
    "    target_date = pd.to_datetime(date).date()\n",
    "    for table_name, table in dfs.items():\n",
    "        df_filtered = table[table[\"start_time\"].dt.date == target_date]\n",
    "        filtered_dfs[table_name] = df_filtered\n",
    "    print(filtered_dfs) \n",
    "    return filtered_dfs   \n",
    "\n",
    "\n",
    "for key, value in phrase_date_pair.items():\n",
    "    if re.fullmatch(pattern, key.lower()) or key in phrases:\n",
    "        print(f'fetch a day: {key} -> {value}') \n",
    "        # now fetch all the entries matching this date \n",
    "        filtered_dfs = filter_df(value,specified_dfs)        \n",
    "    elif 'week' in key:\n",
    "        print('fetch a week:',{key} ,'->', {value})\n",
    "        # now fetch all the entries present on this dates week\n",
    "    elif 'month' in key or re.fullmatch(month_patterns, key.lower()):\n",
    "        print('fetch a month:',{key} ,'->', {value})\n",
    "        # now fetch all the entries matching this dates month\n",
    "\n",
    "\n",
    "r = re.search(range_pattern, Prompt, re.IGNORECASE)\n",
    "if r:\n",
    "    # print('range found:',r.group(0))\n",
    "    print(phrase_date_pair[r.group(1)]) # from date\n",
    "    print(phrase_date_pair[r.group(2)]) # to date\n",
    "\n",
    "    # now fetch all the entries that between from date and to date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
