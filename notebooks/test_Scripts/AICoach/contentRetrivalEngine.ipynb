{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12379723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 17:45:25.020 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-11-20 17:45:25.026 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import os, json, urllib.parse, datetime, re\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from supabase import create_client\n",
    "from streamlit_navigation_bar import st_navbar\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import spacy\n",
    "import dateparser\n",
    "from dateparser.search import search_dates\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9f2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1f65e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findTableNTime(keywords,prompt):\n",
    "#     table_list =[]\n",
    "#     dates = []\n",
    "#     for word in prompt.split(\" \"):\n",
    "#         for table , keys in keywords.items():\n",
    "#             for k in keys:\n",
    "#                 if k in word:\n",
    "#                     table_list.append(table)\n",
    "#     dates = dateparser.search.search_dates(prompt)\n",
    "#     return table_list,dates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3655b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def detect_tables_n_dates(nlp,text):\n",
    "    #keywords : Data,Time,Filter\n",
    "    Keywords_Table = { \"stress\": [\"stress\", \"stress level\", \"stress score\", \"tension\", \"anxiety\", \"strain\", \"mental load\", \"stress pattern\", \"stress zones\", \"stress chart\", \"vitals\"],\n",
    "        \"hr\":[\"heart rate\", \"hr\", \"bpm\", \"resting heart rate\", \"max heart rate\", \"pulse\",\"cardio\", \"hr zone\", \"heart beat\", \"heart-rate\",\"heart\", \"vitals\"],\n",
    "        \"spo2\":[\"spo2\", \"oxygen\", \"blood oxygen\", \"oxygen saturation\", \"o2 level\",\"breathing\", \"respiration\", \"air levels\", \"oxygen dips\", \"oxygen score\", \"vitals\"],\n",
    "        \"steps\":[\"steps\", \"step count\", \"walking\", \"walk\", \"daily steps\", \"distance walked\",\"movement\", \"stride\", \"pedometer\", \"step goal\"],\n",
    "        \"calorie\": [\"calories\", \"calorie burn\", \"energy burn\", \"burned\", \"metabolism\",\"active calories\", \"basal calories\", \"kcal\", \"energy expenditure\", \"fat burn\",\"cal\", \"vitals\"],\n",
    "        \"exercise\": [\"exercise\", \"workout\", \"training\", \"session\", \"sports\", \"activity\",\"reps\", \"sets\", \"routine\", \"intensity\",\"activities\"],    \n",
    "        }\n",
    "    text = text.lower()    \n",
    "    doc = nlp(text)\n",
    "    words_to_dates = {}\n",
    "    dates_total = []\n",
    "    table_list =[]\n",
    "    table_word = \"\" ## to make sure the table name isnt accidently used as a date\n",
    "    for word in text.split(\" \"):\n",
    "        for table , keys in Keywords_Table.items():\n",
    "            for k in keys:\n",
    "                if k in word:\n",
    "                    table_list.append(table)\n",
    "                    table_word = word\n",
    "\n",
    "    ## spacy entity dates + dateparser.parse()\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"DATE\":\n",
    "            parsed = dateparser.parse(ent.text)\n",
    "            if parsed and ent.text not in table_word:\n",
    "                words_to_dates[ent.text] = parsed\n",
    "    # \n",
    "    dp_res = search_dates(text,languages=[\"en\"])\n",
    "    if dp_res:\n",
    "        for phrase, dt in dp_res:\n",
    "            if phrase not in table_word:\n",
    "                words_to_dates[phrase] = dt\n",
    "\n",
    "    ###########################################################\n",
    "    ##REGEX\n",
    "    MONTHS = r\"(?:january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\"\n",
    "\n",
    "\n",
    "    patterns = [\n",
    "        # dd/mm/yyyy | dd-mm-yyyy | dd.mm.yyyy\n",
    "        r\"\\b\\d{1,2}[\\/\\-.]\\d{1,2}[\\/\\-.]\\d{2,4}\\b\",\n",
    "\n",
    "        # yyyy-mm-dd\n",
    "        r\"\\b\\d{4}-\\d{1,2}-\\d{1,2}\\b\",\n",
    "\n",
    "        # 12 Aug 2025\n",
    "        rf\"\\b\\d{{1,2}}(?:st|nd|rd|th)?\\s+{MONTHS}\\s+\\d{{4}}\\b\",\n",
    "\n",
    "        # Aug 12 2025\n",
    "        rf\"\\b{MONTHS}\\s+\\d{{1,2}}(?:st|nd|rd|th)?\\s+\\d{{4}}\\b\",\n",
    "\n",
    "        # August 12, 2025\n",
    "        rf\"\\b{MONTHS}\\s+\\d{{1,2}}(?:st|nd|rd|th)?,\\s+\\d{{4}}\\b\",\n",
    "\n",
    "        # 12th August\n",
    "        rf\"\\b\\d{{1,2}}(?:st|nd|rd|th)?\\s+{MONTHS}\\b\",\n",
    "\n",
    "        # Standalone month\n",
    "        rf\"\\b{MONTHS}\\b\",\n",
    "    ]\n",
    "\n",
    "    found = []\n",
    "    for p in patterns:\n",
    "        matches = re.findall(p, text)\n",
    "        for m in matches:\n",
    "            found.append(m.strip())\n",
    "\n",
    "    # Remove standalone month if part of a larger match\n",
    "    filtered = []\n",
    "    for f in found:\n",
    "        if any((f != other and f in other) for other in found):\n",
    "            continue\n",
    "        filtered.append(f)\n",
    "\n",
    "    # Unique + order preserved    \n",
    "\n",
    "    dates_regex = list(dict.fromkeys(filtered))\n",
    "\n",
    "\n",
    "\n",
    "    # removing duplicates\n",
    "    seen_dates = set()\n",
    "    new_words_2_date_dict = {}\n",
    "    for k , v in words_to_dates.items():\n",
    "        date_only = v.date() # removing hr/min/secs\n",
    "        if date_only not in seen_dates:\n",
    "            new_words_2_date_dict[k] = v\n",
    "            seen_dates.add(date_only)\n",
    "\n",
    "    return table_list,dates_regex,new_words_2_date_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c36bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------------------------------------------------\n",
    "# # TEST SUITE\n",
    "# # -------------------------------------------------------------\n",
    "\n",
    "# test_cases = {\n",
    "#     # Month-only (case variations)\n",
    "#     \"aug\": [\"aug\"],\n",
    "#     \"Aug\": [\"aug\"],\n",
    "#     \"AUG\": [\"aug\"],\n",
    "#     \"august\": [\"august\"],\n",
    "#     \"August\": [\"august\"],\n",
    "\n",
    "#     # All together\n",
    "#     \"aug, Aug, AUG, august, August\": [\"aug\", \"aug\", \"aug\", \"august\", \"august\"],\n",
    "\n",
    "#     # Numeric formats\n",
    "#     \"12/18/25\": [\"12/18/25\"],\n",
    "#     \"01/02/2025\": [\"01/02/2025\"],\n",
    "#     \"1-2-25\": [\"1-2-25\"],\n",
    "#     \"2025-11-18\": [\"2025-11-18\"],\n",
    "\n",
    "#     # Month + day + year\n",
    "#     \"12 Aug 2025\": [\"12 aug 2025\"],\n",
    "#     \"Aug 12 2025\": [\"aug 12 2025\"],\n",
    "#     \"August 12, 2025\": [\"august 12, 2025\"],\n",
    "\n",
    "#     # Ordinal\n",
    "#     \"12th August\": [\"12th august\"],\n",
    "#     \"August 3rd 2024\": [\"august 3 2024\"],\n",
    "\n",
    "#     # Dot/dash\n",
    "#     \"12.10.2025\": [\"12.10.2025\"],\n",
    "#     \"3.1.25\": [\"3.1.25\"],\n",
    "\n",
    "#     # Mixed scenarios\n",
    "#     \"I will come on 1st January 2025 or maybe Feb 2025\":\n",
    "#         [\"1st january 2025\", \"february\"],\n",
    "\n",
    "#     \"Dates: Aug 24, 2024-11-18, 2025\":\n",
    "#         [\"aug 24\", \"2024\", \"2025\"],\n",
    "\n",
    "#     # Noise text\n",
    "#     \"no dates here\":\n",
    "#         []\n",
    "# }\n",
    "\n",
    "# print(\"\\n=== TEST RESULTS ===\")\n",
    "\n",
    "# for text, expected in test_cases.items():\n",
    "#     result = detect_dates_all(Keywords_Table,text)\n",
    "\n",
    "    \n",
    "#     print(f\"\\nInput: {text}\")\n",
    "#     print(f\"Expected: {sorted(set(expected))}\")\n",
    "#     print(f\"Got      : {sorted(set(result))}\")\n",
    "\n",
    "#     if set(result) == set(expected):\n",
    "#         print(\"➡️ PASS\")\n",
    "#     else:\n",
    "#         print(\"❌ FAIL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57789614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MONTHS = {\n",
    "    \"jan\": 1, \"january\": 1,\n",
    "    \"feb\": 2, \"february\": 2,\n",
    "    \"mar\": 3, \"march\": 3,\n",
    "    \"apr\": 4, \"april\": 4,\n",
    "    \"may\": 5,\n",
    "    \"jun\": 6, \"june\": 6,\n",
    "    \"jul\": 7, \"july\": 7,\n",
    "    \"aug\": 8, \"august\": 8,\n",
    "    \"sep\": 9, \"sept\": 9, \"september\": 9,\n",
    "    \"oct\": 10, \"october\": 10,\n",
    "    \"nov\": 11, \"november\": 11,\n",
    "    \"dec\": 12, \"december\": 12\n",
    "}\n",
    "\n",
    "def standardize_date(date_str, current_year=None):    \n",
    "    \n",
    "    # if its datetime.datetime\n",
    "    if isinstance(date_str,datetime):\n",
    "        y = date_str.year\n",
    "        m = date_str.month\n",
    "        d = date_str.day\n",
    "\n",
    "        return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "        \n",
    "    # if its a string\n",
    "    date_str = date_str.lower().strip()\n",
    "\n",
    "    if current_year is None:\n",
    "        current_year = datetime.now().year\n",
    "\n",
    "    # Remove suffixes: 12th -> 12\n",
    "    date_str = re.sub(r\"(\\d+)(st|nd|rd|th)\", r\"\\1\", date_str)\n",
    "\n",
    "    # ---------- CASE 1: YYYY-MM-DD ----------\n",
    "    if re.match(r\"^\\d{4}-\\d{1,2}-\\d{1,2}$\", date_str):\n",
    "        y, m, d = map(int, date_str.split(\"-\"))\n",
    "        return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "\n",
    "    # ---------- CASE 2: DD/MM/YY or DD/MM/YYYY ----------\n",
    "    if \"/\" in date_str:\n",
    "        parts = date_str.split(\"/\")\n",
    "        if len(parts) == 3:\n",
    "            d, m, y = parts\n",
    "            d, m, y = int(d), int(m), int(y)\n",
    "            if y < 100: y += 2000\n",
    "            return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "\n",
    "    # ---------- CASE 3: DD.MM.YY or DD.MM.YYYY ----------\n",
    "    if \".\" in date_str:\n",
    "        parts = date_str.split(\".\")\n",
    "        if len(parts) == 3:\n",
    "            d, m, y = parts\n",
    "            d, m, y = int(d), int(m), int(y)\n",
    "            if y < 100: y += 2000\n",
    "            return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "\n",
    "    # ---------- CASE 4: DD-MM-YY or DD-MM-YYYY ----------\n",
    "    if \"-\" in date_str:\n",
    "        parts = date_str.split(\"-\")\n",
    "        if len(parts) == 3 and not re.match(r\"^\\d{4}-\", date_str):\n",
    "            d, m, y = parts\n",
    "            d, m, y = int(d), int(m), int(y)\n",
    "            if y < 100: y += 2000\n",
    "            return f\"{y:04d}-{m:02d}-{d:02d}\"\n",
    "\n",
    "    # ---------- CASE 5: Mixed Month + Day + Optional Year ----------\n",
    "    tokens = date_str.replace(\",\", \"\").split()\n",
    "\n",
    "    # Find month\n",
    "    month = None\n",
    "    for t in tokens:\n",
    "        if t in MONTHS:\n",
    "            month = MONTHS[t]\n",
    "            break\n",
    "\n",
    "    if month:\n",
    "        # find day (1–31)\n",
    "        day = None\n",
    "        for t in tokens:\n",
    "            if t.isdigit() and 1 <= int(t) <= 31:\n",
    "                day = int(t)\n",
    "                break\n",
    "\n",
    "        # find year ( >31 )\n",
    "        year = None\n",
    "        for t in tokens:\n",
    "            if t.isdigit() and int(t) > 31:\n",
    "                year = int(t)\n",
    "                break\n",
    "\n",
    "        if year is None:\n",
    "            year = current_year\n",
    "\n",
    "        if year < 100:\n",
    "            year += 2000\n",
    "\n",
    "        if day:\n",
    "            return f\"{year:04d}-{month:02d}-{day:02d}\"\n",
    "\n",
    "    # ---------- CASE 6: Only month → return YYYY-MM-01 ----------\n",
    "    if date_str in MONTHS:\n",
    "        return f\"{current_year:04d}-{MONTHS[date_str]:02d}-01\"\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bebca6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standardize_date(\"12 Aug 2025\")      #→ \"2025-08-12\"\n",
    "# # standardize_date(\"12th August\")      # → \"2025-08-12\"  (uses current year)\n",
    "# # standardize_date(\"Aug 24, 2025\")     # → \"2025-08-24\"\n",
    "# # standardize_date(\"1st January 2025\") # → \"2025-01-01\"\n",
    "# # standardize_date(\"3.1.25\")           #→ \"2025-01-03\"\n",
    "# # standardize_date(\"2025-11-18\")       # → \"2025-11-18\"\n",
    "# # standardize_date(\"aug\")               #→ \"2025-08-01\"\n",
    "# # standardize_date(\"Aug 12\")            #→ \"2025-08-12\"  (uses current year)\n",
    "# test_inputs = [\n",
    "#     \"12 Aug 2025\",\n",
    "#     \"12th August\",\n",
    "#     \"Aug 24, 2025\",\n",
    "#     \"1st January 2025\",\n",
    "#     \"3.1.25\",\n",
    "#     \"2025-11-18\",\n",
    "#     \"aug\",\n",
    "#     \"Aug 12\"\n",
    "# ]\n",
    "\n",
    "# for i in test_inputs:\n",
    "#     print(standardize_date(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dce704d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stress', 'hr', 'spo2', 'calorie', 'steps', 'exercise'] \n",
      " {'6 october': '2025-10-06'}\n"
     ]
    }
   ],
   "source": [
    "def parse_prompt(nlp,Prompt):\n",
    "    tables, dates2dates, words2dates = detect_tables_n_dates(nlp,Prompt)\n",
    "    # print(tables)\n",
    "    standardized_dates2dates = {}\n",
    "    for t in dates2dates:\n",
    "        standardized_dates2dates[t] = standardize_date(t)\n",
    "    standardized_words2dates = {}\n",
    "    for key, value in words2dates.items():\n",
    "        standardized_words2dates[key] = standardize_date(value)\n",
    "\n",
    "\n",
    "    final_dates = {**standardized_dates2dates, **standardized_words2dates}\n",
    "    return tables, final_dates\n",
    "\n",
    "\n",
    "# Prompt = input(\"Enter Prompt:\")\n",
    "Prompt = \"How was my hr between 24 nov and 23 nov n this week n yesterday n last week n november n last month\"\n",
    "Prompt = \"stress on 16 weeks ago\"\n",
    "Prompt = \"heart rate from  12 jul to  12 august\"\n",
    "Prompt = \"vitals , steps n exercise at 6 october \"\n",
    "\n",
    "tables , phrase_date_pair = parse_prompt(nlp,Prompt)\n",
    "print(tables, \"\\n\", phrase_date_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3e89df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Now we take the 'phrase : date' pair and create context for filtering the detected tables\n",
    "# print(phrase_date_pair)\n",
    "\n",
    "# ## cases:\n",
    "# ## case 1: data for one or more date to be fetched (all dates which are specified) eg: 24 nov, yesterday\n",
    "# ## case 2: data for one or more week to be fetched (all dates which are specified) eg: last week, this week\n",
    "# ## case 3: data for one or more month to be fetched (all months which are specified) eg : aug, last month, this month\n",
    "# ## case 4: a range of data from one date to another is to be fetched (both dates which are specified) eg: [23 nov, 30 nov], [1 aug, 18 aug]\n",
    "\n",
    "# # logic: \n",
    "# # for fetching dates: check for patterns in phrases like : 24 nov, yesterday, today\n",
    "# # for fetching weeks: check for patterns in phrases like : last week, this week\n",
    "# # for fetching months: check for patterns in phrases like: month names \n",
    "# # for fetching range: check for keywords in received prompt like: from .. to .. \n",
    "\n",
    "# # phrases\n",
    "# pattern = r\"\\b\\d{1,2}\\s+(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|june|july|august|september|october|november|december)\\b\"\n",
    "# phrases = [\"yesterday\",\"today\"]\n",
    "# # month_patterns = r\"(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|may|june|july|august|september|october|november|december)\"\n",
    "\n",
    "# month_patterns = r\"(?:january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\"\n",
    "# range_pattern = rf\"from\\s+((?:\\d{{1,2}}(?:st|nd|rd|th)?\\s+)?{month_patterns})\\s+to\\s+((?:\\d{{1,2}}(?:st|nd|rd|th)?\\s+)?{month_patterns})\"\n",
    "\n",
    "# for key, value in phrase_date_pair.items():\n",
    "#     if re.fullmatch(pattern, key.lower()) or key in phrases:\n",
    "#         print(f'fetch a day: {key}') \n",
    "#         # now fetch all the entries matching this date \n",
    "#     elif 'week' in key:\n",
    "#         print('fetch a week:',key)\n",
    "#         # now fetch all the entries present on this dates week\n",
    "#     elif 'month' in key or re.fullmatch(month_patterns, key.lower()):\n",
    "#         print('fetch a month:',key)\n",
    "#         # now fetch all the entries matching this dates month\n",
    "\n",
    "\n",
    "# r = re.search(range_pattern, Prompt, re.IGNORECASE)\n",
    "# if r:\n",
    "#     # print('range found:',r.group(0))\n",
    "#     print(phrase_date_pair[r.group(1)]) # from date\n",
    "#     print(phrase_date_pair[r.group(2)]) # to date\n",
    "\n",
    "#     # now fetch all the entries that between from date and to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc3de603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def apply_offset(row, offset_col, time_col):\n",
    "    offset_val = row[offset_col]\n",
    "    if pd.isnull(offset_val):\n",
    "        return row[time_col]\n",
    "    offset_str = str(offset_val)\n",
    "    match = None\n",
    "    # Accept both \"UTC+0530\" and \"+05:30\" formats\n",
    "    if offset_str.startswith(\"UTC\"):\n",
    "        match = re.match(r\"UTC([+-])(\\d{2})(\\d{2})\", offset_str)\n",
    "    else:\n",
    "        match = re.match(r\"([+-])(\\d{2}):?(\\d{2})\", offset_str)\n",
    "    if match:\n",
    "        sign, hh, mm = match.groups()\n",
    "        hours, minutes = int(hh), int(mm)\n",
    "        delta = timedelta(hours=hours, minutes=minutes)\n",
    "        if sign == \"-\":\n",
    "            delta = -delta\n",
    "        return row[time_col] + delta\n",
    "    return row[time_col]\n",
    "\n",
    "# -------------------- Cache -----------------------#\n",
    "def get_supabase_client():\n",
    "    load_dotenv()\n",
    "    url = os.getenv(\"url\")\n",
    "    key = os.getenv(\"key\")\n",
    "    return create_client(url, key)\n",
    "\n",
    "def get_engine():\n",
    "    load_dotenv()\n",
    "    return create_engine(\n",
    "        f\"postgresql+psycopg2://{os.getenv('user')}:{urllib.parse.quote_plus(os.getenv('password'))}@{os.getenv('host')}:{os.getenv('port')}/{os.getenv('dbname')}\",\n",
    "        pool_pre_ping=True,  # checks if connection is alive\n",
    "        pool_recycle=1800    # recycle every 30 mins\n",
    "    )\n",
    "\n",
    "\n",
    "def querySupabase(_engine, table: str, columns: list, retries=3):\n",
    "    #Query Supabase/Postgres with retry logic.\n",
    "    cols_str = \",\".join(columns)\n",
    "    query = text(f\"SELECT {cols_str} FROM {table}\")\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            with _engine.connect() as conn:\n",
    "                df = pd.read_sql(query, conn)\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                st.warning(f\"Query failed, retryingg... ({attempt + 1}/{retries}) — {e}\")                \n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                st.error(f\"Query failed after {retries} attempts: {e}\")\n",
    "                raise e\n",
    "\n",
    "\n",
    "# -------------------- Metric Config --------------------#\n",
    "METRICS_CONFIG = {\n",
    "    \"stress\": {\n",
    "        \"table\": \"stress\",\n",
    "        \"columns\": [\"start_time\", \"score\",\"min\",\"max\", \"time_offset\", \"binning_data\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.stress/{0}/{1}\",\n",
    "    },\n",
    "    \"hr\": {\n",
    "        \"table\": \"tracker_heart_rate\",\n",
    "        \"columns\": [\"heart_rate_start_time\", \"heart_rate_heart_rate\", \"heart_rate_min\", \"heart_rate_max\", \"heart_rate_time_offset\", \"heart_rate_heart_beat_count\", \"heart_rate_deviceuuid\", \"heart_rate_binning_data\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.tracker.heart_rate/{0}/{1}\",\n",
    "    },\n",
    "    \"spo2\": {\n",
    "        \"table\": \"tracker_oxygen_saturation\",\n",
    "        \"columns\": [\"oxygen_saturation_start_time\", \"oxygen_saturation_spo2\",\"oxygen_saturation_heart_rate\", \"oxygen_saturation_time_offset\", \"oxygen_saturation_binning\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.tracker.oxygen_saturation/{0}/{1}\",\n",
    "    },\n",
    "    \"steps\": {\n",
    "        \"table\": \"tracker_pedometer_step_count\",\n",
    "        \"columns\": [\"step_count_start_time\", \"step_count_count\",\"run_step\",\"walk_step\",\"step_count_speed\",\"step_count_distance\",\"step_count_calorie\", \"step_count_time_offset\"],\n",
    "        \"jsonPath_template\": \"\",\n",
    "    },\n",
    "    \"calorie\": {\n",
    "        \"table\": \"calories_burned_details\",\n",
    "        \"columns\": [\"calories_burned_day_time\",\"calories_burned_create_time\",\"active_calories_goal\",\"total_exercise_calories\",\"calories_burned_tef_calorie\",\"calories_burned_active_time\",\"calories_burned_rest_calorie\",\"calories_burned_active_calorie\", \"extra_data\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.calories_burned.details/{0}/{1}\",\n",
    "    },\n",
    "    \"exercise\":{\n",
    "        \"table\":\"exercise\",\n",
    "        \"columns\": [\"exercise_start_time\",\"live_data_internal\",\"routine_datauuid\",\"custom_id\",\"exercise_duration\",\"exercise_calorie\",\"exercise_max_heart_rate\",\"exercise_min_heart_rate\",\"exercise_mean_heart_rate\",\"activity_type\",\"exercise_exercise_type\",\"exercise_count\",\"exercise_time_offset\",\"exercise_live_data\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.exercise/{0}/{1}\",        \n",
    "    },\n",
    "    \"exercise_routine\":{\n",
    "        \"table\":\"exercise_routine\",\n",
    "        \"columns\":[\"datauuid\",\"custom_id\",\"total_calorie\",\"activities\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.exercise.routine/{0}/{1}\",        \n",
    "    },\n",
    "    \"custom_exercise\":{\n",
    "        \"table\":\"exercise_custom_exercise\",\n",
    "        \"columns\":[\"custom_name\",\"datauuid\",\"custom_id\",\"custom_type\",\"preference\"],\n",
    "        \"jsonPath_template\": \"com.samsung.shealth.exercise.custom_exercise/{0}/{1}\",                \n",
    "    },\n",
    "    \"inbuilt_exercises\": {\n",
    "    \"table\": \"inbuilt_exercises\",\n",
    "    \"columns\":[\"exercise_type\",\"exercise_name\"],\n",
    "    \"jsonPath_template\" : \"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# -------------------- Warmup --------------------#\n",
    "def warmup():\n",
    "    \"\"\"Load all metrics into session and Supabase client safely.\"\"\"\n",
    "    supabase_client = get_supabase_client()\n",
    "    engine = get_engine()\n",
    "    \n",
    "    dataframes = {}\n",
    "    \n",
    "    def safe_jsonpath(val, template):\n",
    "        \"\"\"Generate jsonPath safely for binning columns.\"\"\"\n",
    "        if pd.isna(val) or val == \"\":\n",
    "            return \"\"\n",
    "        val_str = str(val)\n",
    "        first_char = val_str[0] if len(val_str) > 0 else \"\"\n",
    "        return template.format(first_char, val)\n",
    "    \n",
    "    for metric, cfg in METRICS_CONFIG.items():\n",
    "        # Query columns\n",
    "        df = querySupabase(engine, cfg[\"table\"], cfg[\"columns\"])\n",
    "        \n",
    "        # Add jsonPath column if template exists\n",
    "        if metric == 'exercise':\n",
    "            if cfg[\"jsonPath_template\"]:\n",
    "                bin_col1 = 'exercise_live_data'\n",
    "                bin_col2 = 'live_data_internal'\n",
    "                df['jsonPath_LiveData'] = df[bin_col1].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))\n",
    "                df['jsonPath_LiveInternal'] = df[bin_col2].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))            \n",
    "            else:\n",
    "                df['jsonPath_LiveData'] = \"\"\n",
    "                df['jsonPath_LiveInternal'] = \"\"\n",
    "        elif metric == 'exercise_routine':\n",
    "            if cfg[\"jsonPath_template\"]:\n",
    "                bin_col1 = 'activities'\n",
    "                df['jsonPath_activities'] = df[bin_col1].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))\n",
    "            else:\n",
    "                df['jsonPath_activities'] = \"\"\n",
    "        elif metric == 'custom_exercise':\n",
    "            if cfg[\"jsonPath_template\"]:\n",
    "                bin_col1 = 'preference'\n",
    "                df['jsonPath_preference'] = df[bin_col1].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))\n",
    "            else:\n",
    "                df['jsonPath_preference'] = \"\"                \n",
    "        else:\n",
    "            if cfg[\"jsonPath_template\"]:\n",
    "                bin_col = df.columns[-1]  # assume last column is the binning column\n",
    "                df['jsonPath'] = df[bin_col].apply(lambda x: safe_jsonpath(x, cfg[\"jsonPath_template\"]))\n",
    "            else:\n",
    "                df['jsonPath'] = \"\"\n",
    "\n",
    "        # ----------- Apply offset ONCE per metric -----------\n",
    "        # Stress\n",
    "        if metric == \"stress\" and \"time_offset\" in df.columns and \"start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"time_offset\", \"start_time\"), axis=1)\n",
    "        # Heart Rate\n",
    "        elif metric == \"hr\" and \"heart_rate_time_offset\" in df.columns and \"heart_rate_start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"heart_rate_time_offset\", \"heart_rate_start_time\"), axis=1)\n",
    "        # SpO2\n",
    "        elif metric == \"spo2\" and \"oxygen_saturation_time_offset\" in df.columns and \"oxygen_saturation_start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"oxygen_saturation_time_offset\", \"oxygen_saturation_start_time\"), axis=1)\n",
    "        # Steps\n",
    "        elif metric == \"steps\" and \"step_count_time_offset\" in df.columns and \"step_count_start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"step_count_time_offset\", \"step_count_start_time\"), axis=1)\n",
    "        # Calorie \n",
    "        elif metric == \"calorie\" and \"calories_burned_day_time\" in df.columns:\n",
    "            df[\"localized_time\"] = pd.to_datetime(df[\"calories_burned_day_time\"], errors=\"coerce\")\n",
    "        # Exercise\n",
    "        elif metric == \"exercise\" and \"exercise_time_offset\" in df.columns and \"exercise_start_time\" in df.columns:\n",
    "            df[\"localized_time\"] = df.apply(lambda r: apply_offset(r, \"exercise_time_offset\", \"exercise_start_time\"), axis=1)\n",
    "        # -----------------------------------------------------\n",
    "\n",
    "        dataframes[metric] = df\n",
    "    \n",
    "    return supabase_client, dataframes\n",
    "\n",
    "supabase_client, dataframes = warmup()\n",
    "\n",
    "# removing old start_time and adding the localized time as start_time\n",
    "# removing unnecessary cols from the tables (jsonPath, binning, time offset)\n",
    "df = dataframes\n",
    "for key, value in df.items():\n",
    "    value = value.loc[:,~value.columns.str.contains(\"start_time\")]\n",
    "    value = value.loc[:,~value.columns.str.contains(\"time_offset\")]\n",
    "    value = value.loc[:,~value.columns.str.contains(\"jsonPath\")]\n",
    "    value = value.loc[:,~value.columns.str.contains(\"binning\")]\n",
    "    value = value.loc[:,~value.columns.str.contains(\"uuid\")]\n",
    "    value = value.loc[:,~value.columns.str.contains(\"live_data\")]\n",
    "    \n",
    "\n",
    "    value = value.rename(columns= lambda c: \"start_time\" if \"localized_time\" in c else c)\n",
    "    cols = value.columns.tolist()\n",
    "    if \"start_time\" in cols:\n",
    "        cols.insert(0, cols.pop(cols.index(\"start_time\")))\n",
    "        value = value[cols]\n",
    "    df[key] = value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e7ec544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6 october': '2025-10-06'}\n",
      "fetch a day: 6 october -> 2025-10-06\n",
      "{'stress':              start_time  score   min    max\n",
      "856 2025-10-06 12:00:00   22.0   0.0  100.0\n",
      "857 2025-10-06 13:00:00   70.0  13.0  100.0\n",
      "858 2025-10-06 14:00:00   41.0   0.0  100.0\n",
      "859 2025-10-06 15:00:00   34.0   7.0   61.0\n",
      "860 2025-10-06 17:00:00   53.0   0.0  100.0\n",
      "861 2025-10-06 18:00:00   78.0  15.0  100.0, 'hr':              start_time  heart_rate_heart_rate  heart_rate_min  \\\n",
      "892 2025-10-06 12:00:00                   74.0            59.0   \n",
      "893 2025-10-06 13:00:00                   87.0            78.0   \n",
      "894 2025-10-06 14:00:00                   78.0            55.0   \n",
      "895 2025-10-06 15:00:00                  106.0            77.0   \n",
      "896 2025-10-06 16:00:00                  124.0           103.0   \n",
      "897 2025-10-06 17:00:00                  106.0            55.0   \n",
      "898 2025-10-06 18:00:00                   99.0            79.0   \n",
      "\n",
      "     heart_rate_max  heart_rate_heart_beat_count  \n",
      "892           103.0                            1  \n",
      "893            98.0                            1  \n",
      "894           107.0                            1  \n",
      "895           142.0                            1  \n",
      "896           147.0                            1  \n",
      "897           148.0                            1  \n",
      "898           118.0                            1  , 'spo2': Empty DataFrame\n",
      "Columns: [start_time, oxygen_saturation_spo2, oxygen_saturation_heart_rate]\n",
      "Index: [], 'calorie': Empty DataFrame\n",
      "Columns: [start_time, calories_burned_day_time, calories_burned_create_time, active_calories_goal, total_exercise_calories, calories_burned_tef_calorie, calories_burned_active_time, calories_burned_rest_calorie, calories_burned_active_calorie, extra_data]\n",
      "Index: [], 'steps':                start_time  step_count_count  run_step  walk_step  \\\n",
      "11063 2025-10-06 12:04:00                57         0         57   \n",
      "11064 2025-10-06 12:05:00                19         0         19   \n",
      "11065 2025-10-06 12:06:00                23         0         23   \n",
      "11066 2025-10-06 13:50:00                69         0         69   \n",
      "11067 2025-10-06 13:51:00                40         0         40   \n",
      "...                   ...               ...       ...        ...   \n",
      "11234 2025-10-06 18:28:00                10         0         10   \n",
      "11235 2025-10-06 18:29:00                11         0         11   \n",
      "11236 2025-10-06 18:31:00                12         0         12   \n",
      "11237 2025-10-06 18:32:00                27         0         27   \n",
      "11238 2025-10-06 18:33:00                10         0         10   \n",
      "\n",
      "       step_count_speed  step_count_distance  step_count_calorie  \n",
      "11063          1.500000            42.800000                2.11  \n",
      "11064          1.583333            14.610000                0.73  \n",
      "11065          1.138889            16.360000                0.90  \n",
      "11066          1.500000            53.010000                2.73  \n",
      "11067          1.194444            29.670000                1.48  \n",
      "...                 ...                  ...                 ...  \n",
      "11234          1.333333             7.340000                0.36  \n",
      "11235          1.616008             8.690001                0.35  \n",
      "11236          0.861111             8.050000                0.50  \n",
      "11237          1.000000            18.860000                1.01  \n",
      "11238          1.194444             7.240000                0.36  \n",
      "\n",
      "[174 rows x 7 columns], 'exercise':                  start_time     custom_id  exercise_duration  \\\n",
      "128 2025-10-06 15:32:01.435          None             553977   \n",
      "129 2025-10-06 15:41:14.662          None            1150494   \n",
      "130 2025-10-06 16:00:25.501          None              73126   \n",
      "131 2025-10-06 16:01:38.050   mfuxe9ij_6b             779571   \n",
      "132 2025-10-06 16:14:37.758          None             124334   \n",
      "133 2025-10-06 16:16:41.255   mfuxfjb8_iq             612352   \n",
      "134 2025-10-06 16:26:53.791          None             120000   \n",
      "135 2025-10-06 16:28:56.473          None             455783   \n",
      "136 2025-10-06 16:36:32.563          None               7291   \n",
      "137 2025-10-06 16:36:39.267  mdlkkwe7_1bq             451852   \n",
      "138 2025-10-06 16:44:11.405          None              11299   \n",
      "139 2025-10-06 16:44:22.155   mdlkolrn_gi             505623   \n",
      "140 2025-10-06 16:52:47.951          None             300000   \n",
      "141 2025-10-06 17:01:24.585          None             334942   \n",
      "\n",
      "     exercise_calorie  exercise_max_heart_rate  exercise_min_heart_rate  \\\n",
      "128         72.800000                    142.0                    100.0   \n",
      "129        153.140000                    135.0                     99.0   \n",
      "130         10.740000                    132.0                    125.0   \n",
      "131        114.600000                    146.0                    111.0   \n",
      "132         17.440000                    133.0                    125.0   \n",
      "133         87.990000                    143.0                    114.0   \n",
      "134         15.210000                    130.0                    118.0   \n",
      "135         66.730000                    147.0                    116.0   \n",
      "136          0.141682                    130.0                    129.0   \n",
      "137         58.980000                    132.0                    103.0   \n",
      "138          0.219568                    118.0                    117.0   \n",
      "139         70.620000                    136.0                    108.0   \n",
      "140         37.730000                    128.0                    112.0   \n",
      "141         52.620000                    148.0                    107.0   \n",
      "\n",
      "     exercise_mean_heart_rate  activity_type  exercise_exercise_type  \\\n",
      "128                     117.0           10.0                       0   \n",
      "129                     119.0           20.0                   10011   \n",
      "130                     129.0           40.0                       0   \n",
      "131                     128.0           30.0                       0   \n",
      "132                     129.0           40.0                       0   \n",
      "133                     128.0           30.0                       0   \n",
      "134                     122.0           40.0                       0   \n",
      "135                     129.0           20.0                   10026   \n",
      "136                     129.0           40.0                       0   \n",
      "137                     119.0           30.0                       0   \n",
      "138                     117.0           40.0                       0   \n",
      "139                     119.0           30.0                       0   \n",
      "140                     122.0           50.0                       0   \n",
      "141                     135.0            NaN                   15003   \n",
      "\n",
      "     exercise_count  \n",
      "128             NaN  \n",
      "129            26.0  \n",
      "130             NaN  \n",
      "131            22.0  \n",
      "132             NaN  \n",
      "133            32.0  \n",
      "134             NaN  \n",
      "135            21.0  \n",
      "136             NaN  \n",
      "137            22.0  \n",
      "138             NaN  \n",
      "139            30.0  \n",
      "140             NaN  \n",
      "141             NaN  }\n"
     ]
    }
   ],
   "source": [
    "## Now we take the 'phrase : date' pair and create context for filtering the detected tables\n",
    "print(phrase_date_pair)\n",
    "\n",
    "## cases:\n",
    "## case 1: data for one or more date to be fetched (all dates which are specified) eg: 24 nov, yesterday\n",
    "## case 2: data for one or more week to be fetched (all dates which are specified) eg: last week, this week\n",
    "## case 3: data for one or more month to be fetched (all months which are specified) eg : aug, last month, this month\n",
    "## case 4: a range of data from one date to another is to be fetched (both dates which are specified) eg: [23 nov, 30 nov], [1 aug, 18 aug]\n",
    "\n",
    "# logic: \n",
    "# for fetching dates: check for patterns in phrases like : 24 nov, yesterday, today\n",
    "# for fetching weeks: check for patterns in phrases like : last week, this week\n",
    "# for fetching months: check for patterns in phrases like: month names \n",
    "# for fetching range: check for keywords in received prompt like: from .. to .. \n",
    "\n",
    "# phrases\n",
    "pattern = r\"\\b\\d{1,2}\\s+(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|june|july|august|september|october|november|december)\\b\"\n",
    "phrases = [\"yesterday\",\"today\"]\n",
    "# month_patterns = r\"(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec|january|february|march|april|may|june|july|august|september|october|november|december)\"\n",
    "\n",
    "month_patterns = r\"(?:january|february|march|april|may|june|july|august|september|october|november|december|jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\"\n",
    "range_pattern = rf\"from\\s+((?:\\d{{1,2}}(?:st|nd|rd|th)?\\s+)?{month_patterns})\\s+to\\s+((?:\\d{{1,2}}(?:st|nd|rd|th)?\\s+)?{month_patterns})\"\n",
    "\n",
    "\n",
    "# dataframes = df\n",
    "specified_dfs = {}\n",
    "for table in tables:\n",
    "    if table in df:\n",
    "        specified_dfs[table] = df[table] \n",
    "\n",
    "\n",
    "def filter_df(dfs,type,date = None,start_date=None,end_date=None):\n",
    "    filtered_dfs = {}\n",
    "    if date:\n",
    "        target_date = pd.to_datetime(date).date()\n",
    "        target_iso_year, target_iso_week, _ = target_date.isocalendar()\n",
    "    for table_name, table in dfs.items():\n",
    "        if type == \"range\":\n",
    "            df_filtered = table[(table[\"start_time\"] >= start_date) & (table[\"start_time\"] <= end_date)]\n",
    "        elif type == \"day\":\n",
    "            df_filtered = table[table[\"start_time\"].dt.date == target_date]\n",
    "        elif type == \"week\":\n",
    "            df_filtered = table[(table[\"start_time\"].dt.isocalendar().year == target_iso_year) & (table[\"start_time\"].dt.isocalendar().week == target_iso_week)]\n",
    "        elif type == \"month\":\n",
    "            df_filtered = table[(table[\"start_time\"].dt.year == target_date.year) & (table[\"start_time\"].dt.month == target_date.month)]            \n",
    "        filtered_dfs[table_name] = df_filtered\n",
    "\n",
    "    print(filtered_dfs) \n",
    "    return filtered_dfs   \n",
    "\n",
    "r = re.search(range_pattern, Prompt, re.IGNORECASE)\n",
    "\n",
    "if r:\n",
    "    # print('range found:',r.group(0))  \n",
    "    start_date = phrase_date_pair[r.group(1)] # from date\n",
    "    end_date = phrase_date_pair[r.group(2)]  # to date\n",
    "    # now fetch all the entries that between from date and to date    \n",
    "    filtered_dfs = filter_df(specified_dfs,\"range\",start_date=start_date,end_date=end_date)\n",
    "else:\n",
    "    for key, value in phrase_date_pair.items():\n",
    "        if re.fullmatch(pattern, key.lower()) or key in phrases:\n",
    "            print(f'fetch a day: {key} -> {value}') \n",
    "            # now fetch all the entries matching this date \n",
    "            filtered_dfs = filter_df(specified_dfs,\"day\",date=value)        \n",
    "        elif 'week' in key:\n",
    "            print('fetch a week:',{key} ,'->', {value})\n",
    "            # now fetch all the entries present on this dates week\n",
    "            filtered_dfs = filter_df(specified_dfs,\"week\",date=value)        \n",
    "\n",
    "        elif 'month' in key or re.fullmatch(month_patterns, key.lower()):\n",
    "            print('fetch a month:',{key} ,'->', {value})\n",
    "            # now fetch all the entries matching this dates month\n",
    "            filtered_dfs = filter_df(specified_dfs,\"month\",date=value)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f77fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
